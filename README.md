# ğŸ¸ğŸ§  Comparativa de modelos basados en embeddings para la discriminaciÃ³n del tono de la guitarra elÃ©ctrica
## ğŸ“ Trabajo Fin de Estudios â€” MÃ¡ster en Inteligencia Artificial (UNIR)

### ğŸ‘¤ Autor
Daniel Tenreiro Arcos  
LinkedIn: https://www.linkedin.com/in/danieltenreiro/

---

## ğŸ“Œ DescripciÃ³n
Este repositorio contiene el desarrollo experimental del Trabajo Fin de Estudios centrado en la comparaciÃ³n de modelos de representaciÃ³n de audio basados en deep learning para el anÃ¡lisis de tono en guitarra elÃ©ctrica.

El objetivo principal es evaluar hasta quÃ© punto modelos de embeddings musicales preentrenados capturan informaciÃ³n tÃ­mbrica relevante, diferenciando configuraciones de tono (pastillas, amplificaciÃ³n y cadena de seÃ±al) mÃ¡s allÃ¡ de variaciones de interpretaciÃ³n o pitch.

El trabajo se enfoca en:
- âœ… AnÃ¡lisis cuantitativo mediante recuperaciÃ³n por similitud (Top-K)
- ğŸ§­ Estudio estructural del espacio latente (t-SNE, matrices de confusiÃ³n, etc.)

---

## ğŸ¯ Objetivos
- ğŸ“ˆ Evaluar el comportamiento de distintos modelos de embeddings en tareas de recuperaciÃ³n basada en similitud.
- ğŸ¥‡ğŸ¥ˆ Comparar mÃ©tricas Top-1 y Top-5 sobre conjuntos de validaciÃ³n independientes.
- ğŸ§¬ Analizar la separabilidad del espacio latente mediante tÃ©cnicas de reducciÃ³n de dimensionalidad.
- ğŸ› ï¸ Estudiar el impacto del fine-tuning frente al uso de modelos congelados.
- ğŸ§  Determinar quÃ© arquitectura captura mejor informaciÃ³n tÃ­mbrica especÃ­fica.

---

## ğŸ¤– Modelos evaluados
- ğŸ¼ **MERT (Music Embedding Representation Transformer)** (MERT-v1-330M)
- ğŸ”Š **PANNs (Pretrained Audio Neural Networks)** (CNN14)

Cada modelo se evaluÃ³ bajo diferentes configuraciones:
- ğŸ•’ ExtracciÃ³n de embeddings globales mediante pooling temporal.
- ğŸ“‰ Versiones proyectadas vs. representaciones de alta dimensionalidad.
- ğŸ”§ Configuraciones con y sin fine-tuning parcial.
- ğŸ§ª SeparaciÃ³n explÃ­cita train/validation para evitar fuga de informaciÃ³n.

---

## ğŸ§ª MetodologÃ­a (pipeline)
Flujo experimental general:
1. ğŸ§ ExtracciÃ³n de embeddings a partir de audio procesado
2. ğŸ“ NormalizaciÃ³n de vectores
3. ğŸ“ Similitud coseno entre muestras
4. ğŸ” EvaluaciÃ³n mediante recuperaciÃ³n Top-K (Top-1 / Top-5)
5. ğŸ§¾ Matrices de confusiÃ³n
6. ğŸ—ºï¸ VisualizaciÃ³n del espacio latente (t-SNE)
7. ğŸ§· ComparaciÃ³n baseline vs. fine-tuning

ğŸ“Œ Las mÃ©tricas se calcularon **exclusivamente sobre el conjunto de validaciÃ³n** para garantizar consistencia metodolÃ³gica.

---

## ğŸ§° LibrerÃ­as principales

Las principales librerÃ­as utilizadas a lo largo de los notebooks experimentales son:

- **Procesamiento numÃ©rico y de datos**:
  - `numpy`
  - `pandas`

- **VisualizaciÃ³n**:
  - `matplotlib`

- **Aprendizaje automÃ¡tico y evaluaciÃ³n**:
  - `scikit-learn`

- **Framework de Deep Learning**:
  - `torch` (PyTorch)
  - `torchaudio`

- **ImplementaciÃ³n de modelos**:
  - `transformers`
  - `panns_inference`

- **Procesamiento de audio**:
  - `soundfile`

- **Utilidades**:
  - `tqdm`

---

# ğŸ¸ğŸ§  Comparative Study of Embedding-Based Models for Electric Guitar Tone Discrimination
## ğŸ“ Final Masterâ€™s Project â€” Masterâ€™s Degree in Artificial Intelligence (UNIR)

### ğŸ‘¤ Author
Daniel Tenreiro Arcos  
LinkedIn: https://www.linkedin.com/in/danieltenreiro/

---

## ğŸ“Œ Description
This repository contains the experimental development of the Final Masterâ€™s Project focused on comparing deep learning-based audio representation models for electric guitar tone analysis.

The main objective is to evaluate to what extent pretrained musical embedding models capture relevant timbral information, discriminating tone configurations (pickups, amplification, and signal chain) beyond variations in performance or pitch.

The work focuses on:
- âœ… Quantitative analysis through similarity-based retrieval (Top-K)
- ğŸ§­ Structural study of the latent space (t-SNE, confusion matrices, etc.)

---

## ğŸ¯ Objectives
- ğŸ“ˆ Evaluate the behavior of different embedding models in similarity-based retrieval tasks.
- ğŸ¥‡ğŸ¥ˆ Compare Top-1 and Top-5 metrics on independent validation sets.
- ğŸ§¬ Analyze latent space separability using dimensionality reduction techniques.
- ğŸ› ï¸ Study the impact of fine-tuning compared to frozen models.
- ğŸ§  Determine which architecture better captures timbre-specific information.

---

## ğŸ¤– Evaluated Models
- ğŸ¼ **MERT (Music Embedding Representation Transformer)** (MERT-v1-330M)
- ğŸ”Š **PANNs (Pretrained Audio Neural Networks)** (CNN14)

Each model was evaluated under different configurations:
- ğŸ•’ Extraction of global embeddings using temporal pooling.
- ğŸ“‰ Projected versions vs. high-dimensional representations.
- ğŸ”§ Configurations with and without partial fine-tuning.
- ğŸ§ª Explicit train/validation split to prevent data leakage.

---

## ğŸ§ª Methodology (pipeline)
General experimental workflow:
1. ğŸ§ Extraction of embeddings from processed audio
2. ğŸ“ Vector normalization
3. ğŸ“ Cosine similarity computation between samples
4. ğŸ” Evaluation using Top-K retrieval (Top-1 / Top-5)
5. ğŸ§¾ Confusion matrices
6. ğŸ—ºï¸ Latent space visualization (t-SNE)
7. ğŸ§· Baseline vs. fine-tuned comparison

ğŸ“Œ Metrics were computed **exclusively on the validation set** to ensure methodological consistency.

---

## ğŸ§° Main Libraries

The main libraries used throughout the experimental notebooks are:

- **Numerical & Data Processing**:
  - `numpy`
  - `pandas`

- **Visualization**:
  - `matplotlib`

- **Machine Learning & Evaluation**:
  - `scikit-learn`

- **Deep Learning Framework**:
  - `torch` (PyTorch)
  - `torchaudio`

- **Model Implementations**:
  - `transformers`
  - `panns_inference`

- **Audio Processing**:
  - `soundfile`

- **Utilities**:
  - `tqdm`

